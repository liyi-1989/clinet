V=genV(p=p,r=r,s=s,tele=tele)
S=V%*%t(V)+diag(rep(1,p))
# Step I: Generate data
# method 1: generate data directly with sigma
data = mvrnorm(n, mu = rep(0,p), Sigma = S)
# method 2: generate according to factor model
V=genV(p=p,r=r,s=s,tele=tele)
f=mvrnorm(n, mu = rep(0,p), Sigma = Ip)
E=mvrnorm(n, mu = rep(0,p), Sigma = Ip)
data = V%*%t(f)+sigma*t(E) #mvrnorm(n, mu = rep(0,p), Sigma = S)
data=t(data)
# Step II: Calculate Different Covariance Estimator
# NOTE:  each one has a threshould to tune based on different model
# TYPE 1: sample covariance
Shat=cov(data)
# TYPE 2: (universal) threshoulding sample covariance
ST=Shat*(abs(Shat)>0.37)
# note: large sample size n=1e5, thre=0.1, frob_thre=0.2, could find all, better than threshoulding (not not very interesting)
# TYPE 3: use (3 by 3 block) variance threshoulding
Snorm=MnormM(Shat,h=2,type=4,RM=F)
B1=(Snorm>0.37)
B2=matrix(0,p,p)
for(i in 1:p){
for(j in 1:p){
if(abs(i-j)<=10){
B1[i,j]=0
}
if(abs(i-j)<=2){
B2[i,j]=1
}
}
}
# SB=Shat*(B1 | B2) # B1: teleconnection; B2: banding, cut nearest-neighbours (too good)
SB=Shat*(Snorm>0.26)
# TYPE 4: Tony Cai's Adaptive threshould
SAT=MnormMvar(data) # Calculate variance of covariance elements
SA=regAT(Shat,sqrt(SAT),n,const=1.4)
printM(Shat)
printM(ST)
printM(SB)
printM(SA)
printM(S)
base::norm(S-Shat,"F")
base::norm(S-ST,"F")
base::norm(S-SB,"F")
base::norm(S-SA,"F")
round(S[4:8,89:93],2)
round(Shat[4:8,89:93],2)
round(Snorm[4:8,89:93],2)
# rho=1
p=100; n=1000; r=0.9; s=0.4; tele=1; sigma=1
Ip=diag(rep(1,p))
V=genV(p=p,r=r,s=s,tele=tele)
S=V%*%t(V)+diag(rep(1,p))
# Step I: Generate data
# method 1: generate data directly with sigma
data = mvrnorm(n, mu = rep(0,p), Sigma = S)
# method 2: generate according to factor model
V=genV(p=p,r=r,s=s,tele=tele)
f=mvrnorm(n, mu = rep(0,p), Sigma = Ip)
E=mvrnorm(n, mu = rep(0,p), Sigma = Ip)
data = V%*%t(f)+sigma*t(E) #mvrnorm(n, mu = rep(0,p), Sigma = S)
data=t(data)
# Step II: Calculate Different Covariance Estimator
# NOTE:  each one has a threshould to tune based on different model
# TYPE 1: sample covariance
Shat=cov(data)
# TYPE 2: (universal) threshoulding sample covariance
ST=Shat*(abs(Shat)>0.37)
# note: large sample size n=1e5, thre=0.1, frob_thre=0.2, could find all, better than threshoulding (not not very interesting)
# TYPE 3: use (3 by 3 block) variance threshoulding
Snorm=MnormM(Shat,h=2,type=4,RM=F)
B1=(Snorm>0.38)
B2=matrix(0,p,p)
for(i in 1:p){
for(j in 1:p){
if(abs(i-j)<=10){
B1[i,j]=0
}
if(abs(i-j)<=2){
B2[i,j]=1
}
}
}
# SB=Shat*(B1 | B2) # B1: teleconnection; B2: banding, cut nearest-neighbours (too good)
SB=Shat*(Snorm>0.26)
# TYPE 4: Tony Cai's Adaptive threshould
SAT=MnormMvar(data) # Calculate variance of covariance elements
SA=regAT(Shat,sqrt(SAT),n,const=1.45)
printM(Shat)
printM(ST)
printM(SB)
printM(SA)
printM(S)
base::norm(S-Shat,"F")
base::norm(S-ST,"F")
base::norm(S-SB,"F")
base::norm(S-SA,"F")
round(S[4:8,89:93],2)
round(Shat[4:8,89:93],2)
round(Snorm[4:8,89:93],2)
# rho=-1
p=100; n=1000; r=0.9; s=0.4; tele=-1; sigma=1
Ip=diag(rep(1,p))
V=genV(p=p,r=r,s=s,tele=tele)
S=V%*%t(V)+diag(rep(1,p))
# Step I: Generate data
# method 1: generate data directly with sigma
data = mvrnorm(n, mu = rep(0,p), Sigma = S)
# method 2: generate according to factor model
V=genV(p=p,r=r,s=s,tele=tele)
f=mvrnorm(n, mu = rep(0,p), Sigma = Ip)
E=mvrnorm(n, mu = rep(0,p), Sigma = Ip)
data = V%*%t(f)+sigma*t(E) #mvrnorm(n, mu = rep(0,p), Sigma = S)
data=t(data)
# Step II: Calculate Different Covariance Estimator
# NOTE:  each one has a threshould to tune based on different model
# TYPE 1: sample covariance
Shat=cov(data)
# TYPE 2: (universal) threshoulding sample covariance
ST=Shat*(abs(Shat)>0.38)
# note: large sample size n=1e5, thre=0.1, frob_thre=0.2, could find all, better than threshoulding (not not very interesting)
# TYPE 3: use (3 by 3 block) variance threshoulding
Snorm=MnormM(Shat,h=2,type=4,RM=T)
B1=(Snorm>0.35)
B2=matrix(0,p,p)
for(i in 1:p){
for(j in 1:p){
if(abs(i-j)<=10){
B1[i,j]=0
}
if(abs(i-j)<=2){
B2[i,j]=1
}
}
}
# SB=Shat*(B1 | B2) # B1: teleconnection; B2: banding, cut nearest-neighbours (too good)
SB=Shat*(Snorm>0.26)
# TYPE 4: Tony Cai's Adaptive threshould
SAT=MnormMvar(data) # Calculate variance of covariance elements
SA=regAT(Shat,sqrt(SAT),n,const=1.47)
printM(Shat)
printM(ST)
printM(SB)
printM(SA)
printM(S)
base::norm(S-Shat,"F")
base::norm(S-ST,"F")
base::norm(S-SB,"F")
base::norm(S-SA,"F")
round(S[4:8,89:93],2)
round(Shat[4:8,89:93],2)
round(Snorm[4:8,89:93],2)
# rho=-1
p=100; n=1000; r=0.9; s=0.4; tele=-1; sigma=1
Ip=diag(rep(1,p))
V=genV(p=p,r=r,s=s,tele=tele)
S=V%*%t(V)+diag(rep(1,p))
# Step I: Generate data
# method 1: generate data directly with sigma
data = mvrnorm(n, mu = rep(0,p), Sigma = S)
# method 2: generate according to factor model
V=genV(p=p,r=r,s=s,tele=tele)
f=mvrnorm(n, mu = rep(0,p), Sigma = Ip)
E=mvrnorm(n, mu = rep(0,p), Sigma = Ip)
data = V%*%t(f)+sigma*t(E) #mvrnorm(n, mu = rep(0,p), Sigma = S)
data=t(data)
# Step II: Calculate Different Covariance Estimator
# NOTE:  each one has a threshould to tune based on different model
# TYPE 1: sample covariance
Shat=cov(data)
# TYPE 2: (universal) threshoulding sample covariance
ST=Shat*(abs(Shat)>0.38)
# note: large sample size n=1e5, thre=0.1, frob_thre=0.2, could find all, better than threshoulding (not not very interesting)
# TYPE 3: use (3 by 3 block) variance threshoulding
Snorm=MnormM(Shat,h=2,type=4,RM=T)
B1=(Snorm>0.35)
B2=matrix(0,p,p)
for(i in 1:p){
for(j in 1:p){
if(abs(i-j)<=10){
B1[i,j]=0
}
if(abs(i-j)<=2){
B2[i,j]=1
}
}
}
# SB=Shat*(B1 | B2) # B1: teleconnection; B2: banding, cut nearest-neighbours (too good)
SB=Shat*(Snorm>0.26)
# TYPE 4: Tony Cai's Adaptive threshould
SAT=MnormMvar(data) # Calculate variance of covariance elements
SA=regAT(Shat,sqrt(SAT),n,const=1.47)
printM(Shat)
printM(ST)
printM(SB)
printM(SA)
printM(S)
base::norm(S-Shat,"F")
base::norm(S-ST,"F")
base::norm(S-SB,"F")
base::norm(S-SA,"F")
round(S[4:8,89:93],2)
round(Shat[4:8,89:93],2)
round(Snorm[4:8,89:93],2)
59+40-1
59+52-1
59+60-1
install.packages("QRM")
rGumbelSim <- rGumbel(1000,0,1)
plot(rGumbelSim)
library(QRM)
rGumbelSim <- rGumbel(1000,0,1)
plot(rGumbelSim)
rGumbelSim <- rGumbel(1000,0,1)
plot(density(rGumbelSim))
source('utils_cov.R')
N=1000
res2=rep(0,N)
for(k in 1:N){
data = mvrnorm(n, mu = rep(0,p), Sigma = S)
Shat=cov(data)
# for(i in 1:p){
#   Shat[i,i]=0
# }
# for(i in 1:(p-1)){
#   Shat[i,i+1]=Shat[i+1,i]=0
# }
# for(i in 1:(p-2)){
#   Shat[i,i+2]=Shat[i+2,i]=0
# }
res2[k]=max(abs(Shat*(S==0)))
}
plot(density(res2),col="blue",main="dis of max of zeros in many sample cov")
x=seq(min(res2),max(res2),length=100)
y=dnorm(x,mean=mean(res2), sd=sd(res2))
lines(x,y, type="l", lwd=1,col="red")
abline(v=mean(res2),lty=2,col="orange")
legend("topright",c("dis. of max of zeros","its normal appr."),lty=c(1,1),col=c("blue","red"))
plot(density(res2),col="blue",main="dis of max of zeros in many sample cov")
x=seq(min(res2),max(res2),length=100)
y=dnorm(x,mean=mean(res2), sd=sd(res2))
lines(x,y, type="l", lwd=1,col="red")
abline(v=mean(res2),lty=2,col="orange")
legend("topright",c("dis. of max of zeros","its normal appr."),lty=c(1,1),col=c("blue","red"))
y2=dGumbel(x, mu = mean(res), sigma = sd(res)*sqrt(6)/pi, log = FALSE)
lines(x,y2, type="l", lwd=1,col="pink")
plot(density(res2),lty=2,col="blue",main="dis of max of zeros in many sample cov")
x=seq(min(res2),max(res2),length=100)
y=dnorm(x,mean=mean(res2), sd=sd(res2))
lines(x,y, type="l", lwd=1,col="red")
abline(v=mean(res2),lty=2,col="orange")
legend("topright",c("dis. of max of zeros","its normal appr."),lty=c(2,1),col=c("blue","red"))
y2=dGumbel(x, mu = mean(res), sigma = sd(res)*sqrt(6)/pi, log = FALSE)
lines(x,y2, type="l", lwd=1,col="pink")
plot(density(res2),lty=2,col="blue",main="dis of max of zeros in many sample cov")
x=seq(min(res2),max(res2),length=100)
y=dnorm(x,mean=mean(res2), sd=sd(res2))
lines(x,y, type="l", lwd=1,col="red")
abline(v=mean(res2),lty=2,col="orange")
legend("topright",c("dis. of max of zeros","its normal appr."),lty=c(2,1),col=c("blue","red"))
y2=dGumbel(x, mu = mean(res)-0.5772*sd(res)*sqrt(6)/pi, sigma = sd(res)*sqrt(6)/pi, log = FALSE)
lines(x,y2, type="l", lwd=1,col="pink")
x
plot(density(res2),lty=2,col="blue",main="dis of max of zeros in many sample cov")
x=seq(min(res2),max(res2),length=100)
y=dnorm(x,mean=mean(res2), sd=sd(res2))
lines(x,y, type="l", lwd=1,col="red")
abline(v=mean(res2),lty=2,col="orange")
legend("topright",c("dis. of max of zeros","its normal appr."),lty=c(2,1),col=c("blue","red"))
y2=dGumbel(x, mu = mean(res2)-0.5772*sd(res2)*sqrt(6)/pi, sigma = sd(res2)*sqrt(6)/pi, log = FALSE)
lines(x,y2, type="l", lwd=1,col="pink")
source('utils_cov.R')
# True model (WITH teleconnection)
p=100; n=1000; r=0.9; s=0.5; tele=-1; sigma=1
Ip=diag(rep(1,p))
V=genV(p=p,r=r,s=s,tele=tele)
S=V%*%t(V)+diag(rep(1,p))
M=(S==0)
n=1000
data = mvrnorm(n, mu = rep(0,p), Sigma = S)
Shat=cov(data)
# take zero elements in true cov
res=NULL
for(i in 1:p){
for(j in 1:p){
if(M[i,j] & (i-j>2)){
res=c(res,Shat[i,j])
}
}
}
# result: dis. of zeros like normal
plotDen(res)
source('utils_cov.R')
p=100; n=1000; r=0.9; s=0.5; tele=T; sigma=1
maxnoise(p,type=0, n=1000, N=100,r=r,s=s,tele=tele, sigma=sigma)
source('D:/works/clinet/utils_cov.R')
maxnoise(p,type=0, n=1000, N=100,r=r,s=s,tele=tele, sigma=sigma)
tele=F
maxnoise(p,type=0, n=1000, N=100,r=r,s=s,tele=tele, sigma=sigma)
p=100; n=1000; r=0.9; s=0.5; tele=T; sigma=1
maxnoise(p,type=0, n=1000, N=100,r=r,s=s,tele=tele, sigma=sigma)
maxnoise(p,type=0, n=1000, N=200,r=r,s=s,tele=tele, sigma=sigma)
source('D:/works/clinet/utils_cov.R')
maxnoise(p,type=0, n=1000, N=200,r=r,s=s,tele=tele, sigma=sigma)
source('D:/works/clinet/utils_cov.R')
maxnoise(p,type=0, n=1000, N=200,r=r,s=s,tele=tele, sigma=sigma)
source('D:/works/clinet/utils_cov.R')
maxnoise(p,type=0, n=1000, N=100,r=r,s=s,tele=tele, sigma=sigma)
source('D:/works/clinet/utils_cov.R')
maxnoise(p,type=0, n=1000, N=100,r=r,s=s,tele=tele, sigma=sigma)
tele
maxnoise(p,type=0, n=1000, N=100,r=r,s=s,tele=tele, sigma=sigma)
maxnoise(p,type=4, n=1000, N=100,r=r,s=s,tele=tele, sigma=sigma)
n=1000
for(i in 1:N){
res[i]=max(rnorm(n))
}
plotDen(res)
N
n=1000
for(i in 1:N){
res[i]=max(rnorm(n))
}
plotDen(res)
n=1000
for(i in 1:N){
res[i]=max(rnorm(n))
}
plotDen(res)
n=1000
for(i in 1:N){
res[i]=max(rnorm(n))
}
plotDen(res)
n=1000
for(i in 1:N){
res[i]=max(rnorm(n))
}
plotDen(res)
rnorm(5)
n=1000
N=10000
for(i in 1:N){
res[i]=max(rnorm(n))
}
plotDen(res)
n=1000
N=10000
for(i in 1:N){
res[i]=max(rnorm(n))
}
plotDen(res)
n=10000
N=10000
for(i in 1:N){
res[i]=max(rnorm(n))
}
plotDen(res)
fgev
library("evd", lib.loc="D:/Program Files/R/R-3.3.2/library")
?fgev
fgev(res)
mean(res)
mean(res)-0.5772*sd(res)*sqrt(6)/pi
sd(res)*sqrt(6)/pi
plot(fgev(res))
fgev(res,shape=0)
mean(res)-0.5772*sd(res)*sqrt(6)/pi
sd(res)*sqrt(6)/pi
str(fgev(res,shape=0))
fgev(res,shape=0)$estimate
fgev(res,shape=0)$estimate$loc
class(fgev(res,shape=0)$estimate)
fgev(res,shape=0)$estimate["loc"]
fgev(res,shape=0)$estimate["scale"]
? dGumbel
install.packages("rSymPy")
'hi'
r
f3
library(rSymPy)
r = Var('r')
s = Var('s')
r=0
s=1
f3 = Var('f3')
f4 = Var('f4')
f5 = Var('f5')
f6 = Var('f6')
f7 = Var('f7')
f88 = Var('f88')
f89 = Var('f89')
f90 = Var('f90')
f91 = Var('f91')
f92 = Var('f92')
rGumbelSim <- rGumbel(1000,mu=0,sigma=1)
plot(density(rGumbelSim))
library(evd) #fgev(...)$estimate to fit model parameters
library(QRM) # xGumbel like function
rGumbelSim <- rGumbel(1000,mu=0,sigma=1)
plot(density(rGumbelSim))
fgev(rGumbelSim,shape=0)$estimate
fgev(rGumbelSim)$estimate
?tools::texi2pdf
setwd("D:/Dropbox/papers/RJ")
tools::texi2pdf("RJwrapper.tex")
tools::texi2pdf("RJwrapper.tex")
g <- barabasi.game(1000, power=1)
layout <- layout.fruchterman.reingold(g)
plot(g, layout=layout, vertex.size=2,
vertex.label=NA, edge.arrow.size=.2)
library(igraph)
g <- barabasi.game(1000, power=1)
layout <- layout.fruchterman.reingold(g)
plot(g, layout=layout, vertex.size=2,
vertex.label=NA, edge.arrow.size=.2)
library(igraph)
g <- barabasi.game(1000, power=1)
layout <- layout.fruchterman.reingold(g)
plot(g, layout=layout, vertex.size=2,
vertex.label=NA, edge.arrow.size=.2)
betweenness(g)
B=betweenness(g)
plot(density(B))
EB=edge.betweenness(g)
plot(density(EB))
plot(density(EB))
source("http://michael.hahsler.net/SMU/ScientificCompR/code/map.R")
plot(g, layout=layout,
vertex.size=map(betweenness(g),c(1,15)),
edge.width=map(edge.betweenness(g), c(1,10)))
plot(g, layout=layout,
vertex.size=map(betweenness(g),c(1,15)),
edge.width=map(edge.betweenness(g), c(1,10)),vertex.label=NA,)
eb <- edge.betweenness.community(g)
member <- community.to.membership(g, eb$merges,
step=nrow(eb$merges)-10L+1L)
plot(g,
vertex.color= rainbow(10, .8, .8, alpha=.8)[member$membership+1L],
vertex.size=5, layout=layout,  vertex.label=NA,
edge.arrow.size=.2)
?communities
member=membership(eb)
plot(g,
vertex.color= rainbow(10, .8, .8, alpha=.8)[member$membership+1L],
vertex.size=5, layout=layout,  vertex.label=NA,
edge.arrow.size=.2)
member
plot(g,
vertex.color= rainbow(10, .8, .8, alpha=.8)[member+1L],
vertex.size=5, layout=layout,  vertex.label=NA,
edge.arrow.size=.2)
ec <- evcent(g)$vector
plot(g, layout=layout, vertex.size=map(ec, c(1,20)), vertex.label=NA, edge.arrow.size=.2)
g <- barabasi.game(1000, power=1)
layout <- layout.fruchterman.reingold(g)
plot(g, layout=layout, vertex.size=2,
vertex.label=NA, edge.arrow.size=.2)
B=betweenness(g)
EB=edge.betweenness(g)
plot(density(EB))
plot(g, layout=layout,
vertex.size=map(betweenness(g),c(1,15)),
edge.width=map(edge.betweenness(g), c(1,10)),vertex.label=NA,)
eb <- edge.betweenness.community(g)
#member <- community.to.membership(g, eb$merges, step=nrow(eb$merges)-10L+1L)
member=membership(eb)
plot(g,
vertex.color= rainbow(10, .8, .8, alpha=.8)[member+1L],
vertex.size=5, layout=layout,  vertex.label=NA,
edge.arrow.size=.2)
ec <- evcent(g)$vector
plot(g, layout=layout, vertex.size=map(ec, c(1,20)), vertex.label=NA, edge.arrow.size=.2)
plot(g,
vertex.color= rainbow(10, .8, .8, alpha=.8)[member+2],
vertex.size=5, layout=layout,  vertex.label=NA,
edge.arrow.size=.2)
degree(g)
g <- barabasi.game(1000, power=1)
layout <- layout.fruchterman.reingold(g)
layout <- layout.sphere(g)
plot(g, layout=layout, vertex.size=2,
vertex.label=NA, edge.arrow.size=.2)
g <- barabasi.game(1000, power=1)
layout <- layout.fruchterman.reingold(g)
layout <- layout.sphere(g)
layout <- layout.circle(g)
plot(g, layout=layout, vertex.size=2,
vertex.label=NA, edge.arrow.size=.2)
degree(g)
B=betweenness(g)
EB=edge.betweenness(g)
plot(density(EB))
plot(g, layout=layout,
vertex.size=map(betweenness(g),c(1,15)),
edge.width=map(edge.betweenness(g), c(1,10)),vertex.label=NA,)
eb <- edge.betweenness.community(g)
#member <- community.to.membership(g, eb$merges, step=nrow(eb$merges)-10L+1L)
member=membership(eb)
plot(g,
vertex.color= rainbow(10, .8, .8, alpha=.8)[member+2],
vertex.size=5, layout=layout,  vertex.label=NA,
edge.arrow.size=.2)
ec <- evcent(g)$vector
plot(g, layout=layout, vertex.size=map(ec, c(1,20)), vertex.label=NA, edge.arrow.size=.2)
layout <- layout.sphere(g)
plot(g,
vertex.color= rainbow(10, .8, .8, alpha=.8)[member+2],
vertex.size=5, layout=layout,  vertex.label=NA,
edge.arrow.size=.2)
g
